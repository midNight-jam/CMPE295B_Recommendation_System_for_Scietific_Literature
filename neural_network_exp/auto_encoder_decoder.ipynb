{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5551, 16980)\n"
     ]
    }
   ],
   "source": [
    "matrix = data.read_and_create_user_Matrix()\n",
    "print(matrix.shape)\n",
    "\n",
    "num_input = 16980\n",
    "num_hidden_1=2048\n",
    "num_hidden_2=1024\n",
    "num_hidden_3=512\n",
    "num_hidden_4=256\n",
    "num_hidden_5=128\n",
    "\n",
    "X = tf.placeholder(tf.float64, [None, num_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float64)),\n",
    "    'encoder_h3': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_3], dtype=tf.float64)),\n",
    "    'encoder_h4': tf.Variable(tf.random_normal([num_hidden_3, num_hidden_4], dtype=tf.float64)),\n",
    "    'encoder_h5': tf.Variable(tf.random_normal([num_hidden_4, num_hidden_5], dtype=tf.float64)),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_5, num_hidden_4], dtype=tf.float64)),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_4, num_hidden_3], dtype=tf.float64)),\n",
    "    'decoder_h3': tf.Variable(tf.random_normal([num_hidden_3, num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_h4': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_h5': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float64)),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'encoder_b3': tf.Variable(tf.random_normal([num_hidden_3], dtype=tf.float64)),\n",
    "    'encoder_b4': tf.Variable(tf.random_normal([num_hidden_4], dtype=tf.float64)),\n",
    "    'encoder_b5': tf.Variable(tf.random_normal([num_hidden_5], dtype=tf.float64)),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_4], dtype=tf.float64)),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_hidden_3], dtype=tf.float64)),\n",
    "    'decoder_b3': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float64)),\n",
    "    'decoder_b4': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float64)),\n",
    "    'decoder_b5': tf.Variable(tf.random_normal([num_input], dtype=tf.float64)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
    "    # Encoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
    "    # Encoder Hidden layer with sigmoid activation #3\n",
    "    layer_3 = tf.nn.tanh(tf.add(tf.matmul(layer_2, weights['encoder_h3']), biases['encoder_b3']))\n",
    "    # Encoder Hidden layer with sigmoid activation #4\n",
    "    layer_4 = tf.nn.tanh(tf.add(tf.matmul(layer_3, weights['encoder_h4']), biases['encoder_b4']))\n",
    "    # Encoder Hidden layer with sigmoid activation #5\n",
    "    layer_5 = tf.nn.tanh(tf.add(tf.matmul(layer_4, weights['encoder_h5']), biases['encoder_b5']))\n",
    "    return layer_5\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "\n",
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n",
    "    # Decoder Hidden layer with sigmoid activation #3\n",
    "    layer_3 = tf.nn.tanh(tf.add(tf.matmul(layer_2, weights['decoder_h3']), biases['decoder_b3']))\n",
    "    # Decoder Hidden layer with sigmoid activation #4\n",
    "    layer_4 = tf.nn.tanh(tf.add(tf.matmul(layer_3, weights['decoder_h4']), biases['decoder_b4']))\n",
    "    # Decoder Hidden layer with sigmoid activation #5\n",
    "    layer_5 = tf.nn.sigmoid(tf.add(tf.matmul(layer_4, weights['decoder_h5']), biases['decoder_b5']))\n",
    "    return layer_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float64'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float64'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float64'>.\n",
      "Epoch: 1 Loss: 0.103666024291\n",
      "Epoch: 2 Loss: 0.102816157011\n",
      "Epoch: 3 Loss: 0.10150044176\n",
      "Epoch: 4 Loss: 0.0993673538233\n",
      "Epoch: 5 Loss: 0.0959262223471\n",
      "Predictions...\n",
      "         0         1         2         3         4         5         6      \\\n",
      "0     1.000000  0.000000  1.000000  0.000000  1.000000  0.999998  0.000000   \n",
      "1     0.000000  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000   \n",
      "2     0.000000  0.997093  1.000000  0.000000  0.000000  1.000000  0.000000   \n",
      "3     0.000000  1.000000  0.000000  0.000000  0.000000  1.000000  1.000000   \n",
      "4     0.000000  0.000000  0.000000  1.000000  0.000000  0.989980  1.000000   \n",
      "5     0.000000  1.000000  0.000000  0.000000  0.000000  0.000000  0.972949   \n",
      "6     0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000   \n",
      "7     0.000000  0.000000  1.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "8     0.000000  0.000000  0.000000  0.000000  1.000000  1.000000  0.000000   \n",
      "9     0.000000  0.000000  0.000000  0.000000  0.998324  1.000000  0.000000   \n",
      "10    0.000000  1.000000  1.000000  0.000000  1.000000  0.000000  0.000000   \n",
      "11    0.000000  0.000000  0.000000  0.974744  0.000000  1.000000  1.000000   \n",
      "12    0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000   \n",
      "13    0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000   \n",
      "14    0.000000  1.000000  1.000000  0.000000  0.000000  1.000000  0.000000   \n",
      "15    0.000000  0.000000  1.000000  0.000000  1.000000  0.000000  0.999992   \n",
      "16    0.000000  0.000000  0.000000  0.000000  0.350647  0.000000  1.000000   \n",
      "17    1.000000  0.000000  0.363074  0.000000  0.000000  0.000000  1.000000   \n",
      "18    0.000000  0.000000  1.000000  0.000000  0.000000  0.999994  0.000000   \n",
      "19    0.000000  1.000000  0.000000  0.000000  1.000000  0.999995  1.000000   \n",
      "20    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "21    0.000000  0.000000  1.000000  0.000000  0.000000  0.000000  1.000000   \n",
      "22    0.000000  1.000000  1.000000  1.000000  1.000000  0.000000  0.000000   \n",
      "23    0.000000  0.000000  1.000000  0.000000  0.999538  1.000000  1.000000   \n",
      "24    0.000000  1.000000  0.999164  1.000000  0.000000  0.000000  0.000000   \n",
      "25    0.000000  0.995524  0.000000  1.000000  1.000000  0.000000  1.000000   \n",
      "26    0.000000  1.000000  0.000000  1.000000  0.000000  0.000000  1.000000   \n",
      "27    0.000000  0.000000  0.000000  0.999933  0.000000  0.996607  0.000000   \n",
      "28    1.000000  0.999662  0.988115  0.000000  1.000000  0.865500  1.000000   \n",
      "29    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "5521  0.000000  0.999822  1.000000  0.126237  0.000000  0.000000  0.000000   \n",
      "5522  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000   \n",
      "5523  0.000000  0.976787  1.000000  0.000000  0.999994  1.000000  1.000000   \n",
      "5524  0.000000  0.000000  1.000000  0.000000  1.000000  0.000000  0.000000   \n",
      "5525  1.000000  0.000000  0.000000  1.000000  1.000000  0.000000  0.000000   \n",
      "5526  0.000000  0.000000  1.000000  1.000000  0.000000  1.000000  0.000000   \n",
      "5527  0.000000  0.000000  0.000000  0.976625  0.000000  0.950988  0.000000   \n",
      "5528  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  1.000000   \n",
      "5529  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5530  0.000000  0.000000  0.820651  0.000000  0.000000  0.000000  0.000000   \n",
      "5531  0.000000  0.000000  0.000000  1.000000  0.235734  1.000000  0.000000   \n",
      "5532  0.999981  1.000000  0.997235  0.000000  0.982818  0.000000  1.000000   \n",
      "5533  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "5534  0.000000  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5535  0.000000  0.000000  0.000000  0.995987  1.000000  0.000000  0.000000   \n",
      "5536  0.000000  0.000000  0.000000  0.000000  0.000000  0.999970  0.984628   \n",
      "5537  1.000000  1.000000  0.000000  1.000000  0.999976  1.000000  1.000000   \n",
      "5538  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.128142   \n",
      "5539  1.000000  0.000000  1.000000  0.999999  1.000000  0.000000  1.000000   \n",
      "5540  0.000000  0.000000  0.000000  0.000000  0.980402  0.000000  0.999882   \n",
      "5541  1.000000  0.000000  1.000000  0.812710  1.000000  0.000000  1.000000   \n",
      "5542  0.000000  1.000000  0.000000  1.000000  1.000000  0.000000  0.000000   \n",
      "5543  0.000000  1.000000  1.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5544  0.000000  0.000000  0.998672  0.000000  1.000000  1.000000  0.000000   \n",
      "5545  0.416200  0.943492  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5546  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5547  0.999996  0.949014  0.000000  1.000000  1.000000  0.000000  1.000000   \n",
      "5548  0.000000  0.000000  0.967723  1.000000  0.999820  0.000000  0.000000   \n",
      "5549  1.000000  0.994706  0.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "5550  0.000000  0.000000  0.000000  0.000000  0.982066  0.000000  0.332486   \n",
      "\n",
      "         7         8         9        ...        16970     16971     16972  \\\n",
      "0     0.000000  0.000000  0.000000    ...     0.000000  0.000000  1.000000   \n",
      "1     0.000000  0.000000  0.000000    ...     0.000000  0.995125  0.000000   \n",
      "2     0.999999  1.000000  0.998319    ...     0.000000  0.999422  1.000000   \n",
      "3     0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "4     1.000000  1.000000  0.000000    ...     1.000000  0.000000  0.936984   \n",
      "5     0.000000  0.000000  0.000000    ...     0.000000  1.000000  0.000000   \n",
      "6     0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "7     0.000000  0.000000  0.000000    ...     0.000000  1.000000  0.000000   \n",
      "8     1.000000  0.000000  0.000000    ...     1.000000  0.000000  0.999946   \n",
      "9     0.000000  0.000000  0.999997    ...     1.000000  0.972174  0.000000   \n",
      "10    0.000000  0.000000  1.000000    ...     0.000000  1.000000  0.000000   \n",
      "11    1.000000  0.000000  1.000000    ...     1.000000  1.000000  1.000000   \n",
      "12    0.000000  0.000000  0.000000    ...     0.000000  1.000000  0.000000   \n",
      "13    0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "14    0.000000  0.141488  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "15    0.000000  1.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "16    1.000000  0.000000  0.000000    ...     0.756977  0.000000  0.000000   \n",
      "17    0.000000  0.000000  1.000000    ...     0.000000  0.000000  0.000000   \n",
      "18    1.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "19    1.000000  0.000000  1.000000    ...     0.992996  0.000000  0.000000   \n",
      "20    0.000000  0.000000  0.000000    ...     0.000000  1.000000  0.000000   \n",
      "21    0.999905  1.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "22    1.000000  1.000000  0.000000    ...     1.000000  0.999947  0.000000   \n",
      "23    0.000000  1.000000  1.000000    ...     0.000000  0.000000  1.000000   \n",
      "24    0.000000  0.000000  0.000000    ...     0.000000  1.000000  0.000000   \n",
      "25    0.000000  0.756219  0.000000    ...     1.000000  0.999999  0.000000   \n",
      "26    0.887451  0.000000  0.000000    ...     0.000000  1.000000  0.935322   \n",
      "27    0.275814  0.000000  0.151067    ...     0.000000  0.000000  0.000000   \n",
      "28    1.000000  0.000000  0.000000    ...     0.999998  0.000000  0.176185   \n",
      "29    0.000000  0.000000  0.000000    ...     1.000000  0.000000  0.000000   \n",
      "...        ...       ...       ...    ...          ...       ...       ...   \n",
      "5521  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "5522  0.000000  0.000000  0.000000    ...     1.000000  0.000000  0.999987   \n",
      "5523  0.000000  0.000000  1.000000    ...     0.000000  0.998882  0.000000   \n",
      "5524  0.000000  1.000000  0.000000    ...     1.000000  0.000000  0.000000   \n",
      "5525  0.999760  1.000000  0.000000    ...     1.000000  1.000000  0.000000   \n",
      "5526  0.000000  0.000000  0.000000    ...     0.789736  0.000000  0.000000   \n",
      "5527  0.000000  0.000000  0.000000    ...     0.000000  1.000000  0.000000   \n",
      "5528  0.997409  1.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "5529  0.000000  0.000000  1.000000    ...     1.000000  1.000000  0.000000   \n",
      "5530  0.000000  1.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "5531  0.000000  1.000000  1.000000    ...     1.000000  0.700548  0.000000   \n",
      "5532  1.000000  0.470264  1.000000    ...     0.000000  0.000000  1.000000   \n",
      "5533  0.000000  1.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "5534  0.144997  0.000000  0.428675    ...     0.000000  0.000000  0.000000   \n",
      "5535  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "5536  0.000000  0.000000  0.185455    ...     1.000000  0.000000  0.000000   \n",
      "5537  0.000000  0.000000  0.000000    ...     1.000000  0.000000  0.000000   \n",
      "5538  0.000000  1.000000  1.000000    ...     1.000000  1.000000  0.984770   \n",
      "5539  0.000000  0.000000  0.761365    ...     0.000000  0.000000  0.999983   \n",
      "5540  0.000000  0.000000  0.000000    ...     1.000000  1.000000  1.000000   \n",
      "5541  1.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "5542  0.000000  0.000000  0.000000    ...     1.000000  0.000000  0.000000   \n",
      "5543  1.000000  0.000000  0.219931    ...     0.000000  1.000000  0.000000   \n",
      "5544  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "5545  0.000000  0.000000  0.999998    ...     0.000000  1.000000  1.000000   \n",
      "5546  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
      "5547  0.999998  0.000000  0.000000    ...     0.000000  0.000000  1.000000   \n",
      "5548  1.000000  1.000000  0.998497    ...     0.000000  0.000000  1.000000   \n",
      "5549  0.000000  0.000000  1.000000    ...     0.000000  0.000000  1.000000   \n",
      "5550  1.000000  1.000000  1.000000    ...     0.000000  0.000000  0.971788   \n",
      "\n",
      "         16973     16974     16975     16976     16977     16978     16979  \n",
      "0     0.999999  0.000000  0.000000  1.000000  0.000000  1.000000  0.000000  \n",
      "1     0.998169  0.000000  0.000000  0.000000  0.000000  0.994581  0.000000  \n",
      "2     0.000000  0.000000  0.999999  0.944186  0.000000  0.000000  0.000000  \n",
      "3     0.000000  0.870567  0.000000  0.000000  0.000000  0.167583  0.000000  \n",
      "4     1.000000  0.000000  0.994919  1.000000  1.000000  0.000000  0.000000  \n",
      "5     0.000000  0.000000  0.000000  0.204863  0.000000  1.000000  0.000000  \n",
      "6     0.000000  1.000000  0.000000  1.000000  0.000000  1.000000  0.000000  \n",
      "7     0.999825  0.000000  1.000000  1.000000  0.999965  0.000000  0.000000  \n",
      "8     1.000000  0.000000  0.197269  0.000000  1.000000  0.000000  1.000000  \n",
      "9     0.000000  1.000000  0.000000  0.000000  1.000000  1.000000  0.000000  \n",
      "10    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "11    1.000000  0.000000  1.000000  0.943111  1.000000  0.000000  0.991421  \n",
      "12    1.000000  1.000000  0.000000  0.000000  0.000000  0.000000  1.000000  \n",
      "13    0.000000  0.000000  0.000000  0.000000  1.000000  1.000000  0.000000  \n",
      "14    1.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000  \n",
      "15    0.995239  0.000000  0.000000  1.000000  0.000000  0.000000  0.000000  \n",
      "16    0.000000  0.000000  0.988106  0.999927  1.000000  0.000000  0.000000  \n",
      "17    1.000000  0.000000  0.996771  0.000000  0.999999  0.000000  0.999998  \n",
      "18    1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.846673  \n",
      "19    1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.404380  \n",
      "20    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "21    1.000000  0.000000  1.000000  1.000000  0.946525  0.000000  1.000000  \n",
      "22    0.000000  0.000000  1.000000  0.000000  1.000000  1.000000  0.000000  \n",
      "23    0.000000  0.742359  0.706091  1.000000  0.000000  0.000000  0.000000  \n",
      "24    0.000000  0.000000  1.000000  0.000000  1.000000  0.000000  0.000000  \n",
      "25    1.000000  0.000000  1.000000  0.000000  0.000000  1.000000  0.000000  \n",
      "26    1.000000  0.000000  0.331391  0.814870  1.000000  0.000000  0.999971  \n",
      "27    0.000000  0.879340  0.000000  0.000000  0.000000  1.000000  0.998808  \n",
      "28    0.000000  0.000000  0.000000  1.000000  0.999998  1.000000  0.000000  \n",
      "29    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "5521  0.689840  0.000000  0.999977  0.000000  1.000000  0.265648  0.000000  \n",
      "5522  1.000000  0.000000  0.828460  1.000000  0.000000  0.380665  0.000000  \n",
      "5523  0.000000  1.000000  1.000000  0.000000  1.000000  1.000000  0.000000  \n",
      "5524  0.000000  1.000000  0.489911  0.736360  0.947799  0.000000  1.000000  \n",
      "5525  1.000000  0.000000  0.000000  1.000000  0.979418  0.999757  1.000000  \n",
      "5526  0.000000  1.000000  0.000000  0.999479  0.000000  0.000000  0.000000  \n",
      "5527  0.000000  1.000000  0.999869  0.000000  0.000000  0.000000  0.000000  \n",
      "5528  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  1.000000  \n",
      "5529  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "5530  0.000000  0.991545  0.000000  1.000000  0.999980  0.000000  0.000000  \n",
      "5531  0.000000  1.000000  0.000000  1.000000  0.000000  0.000000  1.000000  \n",
      "5532  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000  \n",
      "5533  0.999653  0.998771  0.000000  1.000000  0.000000  0.000000  0.000000  \n",
      "5534  0.000000  1.000000  0.000000  0.000000  0.000000  0.999978  0.764815  \n",
      "5535  0.000000  1.000000  1.000000  0.000000  0.000000  0.000000  1.000000  \n",
      "5536  1.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.781100  \n",
      "5537  1.000000  0.000000  0.000000  1.000000  1.000000  1.000000  0.000000  \n",
      "5538  0.000000  0.000000  1.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "5539  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  \n",
      "5540  1.000000  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "5541  1.000000  0.994269  0.000000  1.000000  1.000000  0.000000  0.000000  \n",
      "5542  1.000000  1.000000  0.997111  0.000000  0.000000  0.940391  1.000000  \n",
      "5543  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000  \n",
      "5544  0.000000  0.000000  0.000000  0.000000  0.854638  0.999387  0.000000  \n",
      "5545  1.000000  0.000000  1.000000  0.999997  0.000000  1.000000  1.000000  \n",
      "5546  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.000000  \n",
      "5547  0.999055  0.000000  0.000000  1.000000  0.672749  0.000000  1.000000  \n",
      "5548  0.000000  0.000000  1.000000  1.000000  1.000000  0.000000  0.000000  \n",
      "5549  1.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "5550  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[5551 rows x 16980 columns]\n"
     ]
    }
   ],
   "source": [
    "# Construct model\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    encoder_op = encoder(X)\n",
    "    decoder_op = decoder(encoder_op)\n",
    "\n",
    "\n",
    "    # Prediction\n",
    "\n",
    "    y_pred = decoder_op\n",
    "\n",
    "\n",
    "    # Targets are the input data.\n",
    "\n",
    "    y_true = X\n",
    "\n",
    "\n",
    "    # Define loss and optimizer, minimize the squared error\n",
    "\n",
    "\n",
    "    # loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "    loss = tf.losses.sigmoid_cross_entropy(y_true, y_pred)\n",
    "\n",
    "\n",
    "    # optimizer = tf.train.RMSPropOptimizer(0.003).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.1).minimize(loss)\n",
    "    # optimizer = tf.train.AdagradOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "\n",
    "    predictions = pd.DataFrame()\n",
    "\n",
    "    # Define evaluation metrics\n",
    "\n",
    "    eval_x = tf.placeholder(tf.int32, )\n",
    "    eval_y = tf.placeholder(tf.int32, )\n",
    "    pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    local_init = tf.local_variables_initializer()\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as session:\n",
    "    epochs = 5\n",
    "    batch_size = 24\n",
    "\n",
    "    session.run(init)\n",
    "    session.run(local_init)\n",
    "\n",
    "    num_batches = int(matrix.shape[0] / batch_size)\n",
    "    matrix = np.array_split(matrix, batch_size)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "\n",
    "        for batch in matrix:\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"Epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "\n",
    "    print(\"Predictions...\")\n",
    "\n",
    "    matrix = np.concatenate(matrix, axis=0)\n",
    "\n",
    "    preds = session.run(decoder_op, feed_dict={X: matrix})\n",
    "    preds[preds<=0.1]=0.0\n",
    "    #preds = preds.astype('<H')\n",
    "    \n",
    "    predictions = predictions.append(pd.DataFrame(preds))\n",
    "\n",
    "    print(predictions)\n",
    "    predictions.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_data=pd.read_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data=np.array(read_data.loc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97947a2410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(user_data, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neWkhLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9852a0bb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}